{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "\n",
    "from lstm_naivebayes import LSTMClassifier, NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm\n",
    "vocab = {\"あああ\":0, \"いいい\":1, \"ううう\":2, \"えええ\":3}\n",
    "lstm = LSTMClassifier(vocab_size=len(vocab))\n",
    "\n",
    "optimizer = Adam(lstm.parameters())\n",
    "criteriton = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データ\n",
    "X = [\n",
    "        [\"あああ\", \"えええ\", \"ううう\", \"ううう\"], \n",
    "        [\"えええ\", \"えええ\", \"ううう\", \"えええ\"], \n",
    "        [\"いいい\", \"えええ\", \"あああ\", \"あああ\"]\n",
    "    ]\n",
    "y = [\"waka\", \"tanka\", \"waka\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 2, 2], [3, 3, 2, 3], [1, 3, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "#token化\n",
    "X_token = [[vocab[token] for token in row] for row in X]\n",
    "print(X_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練\n",
    "lstm.fit(X_token, y, epochs=70, optimizer=optimizer, criterion=criteriton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['waka', 'tanka'], dtype='<U5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#予測対象データ\n",
    "tar_X = [\n",
    "            [\"あああ\", \"えええ\", \"いいい\", \"ううう\"], \n",
    "            [\"いいい\", \"ううう\", \"えええ\", \"えええ\"]\n",
    "        ]\n",
    "tar_X_token = [[vocab[token] for token in row] for row in tar_X]\n",
    "\n",
    "#予測\n",
    "lstm.predict(tar_X_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "nv = NaiveBayes()\n",
    "\n",
    "#訓練データ\n",
    "X = [[1,0,2,1], [0,0,1,3], [2,1,0,1]] #bag-of-words (tokenIDではない)\n",
    "y = [\"waka\", \"tanka\", \"waka\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['waka', 'waka'], dtype='<U4')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#訓練\n",
    "nv.fit(X, y)\n",
    "\n",
    "#予測対象データ\n",
    "tar_X = [[1,1,1,1], [0,1,1,2]] #bag-of-words\n",
    "\n",
    "#予測\n",
    "nv.predict(tar_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc9d1806f095425deab0f8eb98ab083de74ce933b8139dcc868d2cf9777a6ee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
